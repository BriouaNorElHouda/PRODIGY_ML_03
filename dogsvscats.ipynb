{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3362,"databundleVersionId":31148,"sourceType":"competition"}],"dockerImageVersionId":30788,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import zipfile\nimport os\nimport cv2\nimport numpy as np\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom tqdm import tqdm\nfrom sklearn.decomposition import PCA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:13:47.757342Z","iopub.execute_input":"2024-11-23T22:13:47.758052Z","iopub.status.idle":"2024-11-23T22:13:49.513624Z","shell.execute_reply.started":"2024-11-23T22:13:47.758017Z","shell.execute_reply":"2024-11-23T22:13:49.512748Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\n# Paths to the zip files\ntrain_zip = '/kaggle/input/dogs-vs-cats/train.zip'\ntest_zip = '/kaggle/input/dogs-vs-cats/test1.zip'\n\n# Extract directories\ntrain_dir = '/kaggle/working/train'\ntest_dir = '/kaggle/working/test'\n\n# Unzipping the training dataset\nwith zipfile.ZipFile(train_zip, 'r') as zip_ref:\n    zip_ref.extractall(train_dir)\n\n# Unzipping the test dataset\nwith zipfile.ZipFile(test_zip, 'r') as zip_ref:\n    zip_ref.extractall(test_dir)\n\nprint(\"Data unzipped!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:13:56.542270Z","iopub.execute_input":"2024-11-23T22:13:56.543119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths to the directories\ntrain_dir = '/kaggle/working/train/train'\ntest_dir = '/kaggle/working/test'\n\n# Check the files in the train and test directories\ntrain_images = os.listdir(train_dir)\ntest1_dir = os.path.join(test_dir, 'test1')\n\n# Check contents of test1\ntest_images = os.listdir(test1_dir)\n\n# Print the number of images and a few examples to verify\nprint(f\"Number of training images: {len(train_images)}\")\nprint(f\"Number of test images: {len(test_images)}\")\n\n# Display a few examples\nprint(\"First 5 training images:\", train_images[:5])\nprint(\"First 5 test images:\", test_images[:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:11:12.830550Z","iopub.execute_input":"2024-11-23T22:11:12.830882Z","iopub.status.idle":"2024-11-23T22:11:12.856626Z","shell.execute_reply.started":"2024-11-23T22:11:12.830854Z","shell.execute_reply":"2024-11-23T22:11:12.855626Z"}},"outputs":[{"name":"stdout","text":"Number of training images: 25000\nNumber of test images: 12500\nFirst 5 training images: ['dog.6650.jpg', 'dog.4529.jpg', 'dog.5302.jpg', 'dog.1894.jpg', 'dog.5846.jpg']\nFirst 5 test images: ['3057.jpg', '4893.jpg', '454.jpg', '11706.jpg', '3471.jpg']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\n# Function to load and preprocess images\ndef load_and_preprocess_images(image_paths, target_size=(128, 128)):\n    images = []\n    for image_path in image_paths:\n        # Load image using OpenCV\n        img = cv2.imread(image_path)\n        \n        # Check if the image was loaded successfully\n        if img is None:\n            print(f\"Warning: Could not load image {image_path}\")\n            continue\n        \n        # Resize the image\n        img_resized = cv2.resize(img, target_size)\n        \n        # Normalize pixel values to [0, 1]\n        img_normalized = img_resized / 255.0\n        \n        # Flatten the image to a 1D array (for SVM)\n        img_flattened = img_normalized.flatten()\n        \n        images.append(img_flattened)\n    \n    return np.array(images)\n\n# Correct path to training images\ntrain_dir = '/kaggle/working/train/train'\ntrain_image_paths = [os.path.join(train_dir, img) for img in train_images]\nX_train = load_and_preprocess_images(train_image_paths)\n\n# Check the shape of the first preprocessed image\nprint(f\"Shape of first preprocessed image: {X_train[0].shape}\")\nprint(f\"Total number of training images: {X_train.shape[0]}\")\n\n# Correct path to test images\ntest1_dir = '/kaggle/working/test/test1'\ntest_image_paths = [os.path.join(test1_dir, img) for img in test_images]\nX_test = load_and_preprocess_images(test_image_paths)\n\nprint(f\"Total number of test images: {X_test.shape[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:11:19.504811Z","iopub.execute_input":"2024-11-23T22:11:19.505696Z","iopub.status.idle":"2024-11-23T22:12:09.868442Z","shell.execute_reply.started":"2024-11-23T22:11:19.505661Z","shell.execute_reply":"2024-11-23T22:12:09.867424Z"}},"outputs":[{"name":"stdout","text":"Shape of first preprocessed image: (49152,)\nTotal number of training images: 25000\nTotal number of test images: 12500\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\n# Step 1: Extract labels\ndef extract_labels(image_paths):\n    labels = []\n    for path in tqdm(image_paths, desc=\"Extracting labels\"):\n        filename = os.path.basename(path)\n        if filename.startswith('cat'):\n            labels.append(0)  # 0 for cats\n        elif filename.startswith('dog'):\n            labels.append(1)  # 1 for dogs\n        else:\n            print(f\"Warning: Unknown label in filename {filename}\")\n    return np.array(labels)\n\n# Extract labels for training images\ny_train = extract_labels(train_image_paths)\n\n# Step 2: Split into training and validation sets\nX_train_split, X_val, y_train_split, y_val = train_test_split(\n    X_train, y_train, test_size=0.2, random_state=42\n)\n\nprint(f\"Training set size: {X_train_split.shape[0]}\")\nprint(f\"Validation set size: {X_val.shape[0]}\")\n\n# Optional: Reduce dimensionality with PCA for faster training\nprint(\"Applying PCA to reduce feature dimensions...\")\npca = PCA(n_components=100, random_state=42)  # Use 100 principal components\nX_train_pca = pca.fit_transform(X_train_split)\nX_val_pca = pca.transform(X_val)\n\n# Step 3: Train the SVM classifier\nprint(\"Training the SVM classifier...\")\nstart_time = time.time()\n\nsvm_model = SVC(kernel='linear', C=1.0, random_state=42)\nsvm_model.fit(X_train_pca, y_train_split)\n\ntraining_time = time.time() - start_time\nprint(f\"Training completed in {training_time:.2f} seconds\")\n\n# Step 4: Evaluate on the validation set\nval_accuracy = svm_model.score(X_val_pca, y_val)\nprint(f\"Validation Accuracy: {val_accuracy:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:13:22.811899Z","iopub.execute_input":"2024-11-23T22:13:22.812290Z"}},"outputs":[{"name":"stderr","text":"Extracting labels: 100%|██████████| 25000/25000 [00:00<00:00, 977137.48it/s]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}