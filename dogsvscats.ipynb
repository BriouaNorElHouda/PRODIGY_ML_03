{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3362,"databundleVersionId":31148,"sourceType":"competition"}],"dockerImageVersionId":30788,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import zipfile\nimport os\nimport cv2\nimport numpy as np\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom tqdm import tqdm\nfrom sklearn.decomposition import PCA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:22:02.129173Z","iopub.execute_input":"2024-11-23T22:22:02.130128Z","iopub.status.idle":"2024-11-23T22:22:02.135441Z","shell.execute_reply.started":"2024-11-23T22:22:02.130081Z","shell.execute_reply":"2024-11-23T22:22:02.134327Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\n# Paths to the zip files\ntrain_zip = '/kaggle/input/dogs-vs-cats/train.zip'\ntest_zip = '/kaggle/input/dogs-vs-cats/test1.zip'\n\n# Extract directories\ntrain_dir = '/kaggle/working/train'\ntest_dir = '/kaggle/working/test'\n\n# Unzipping the training dataset\nwith zipfile.ZipFile(train_zip, 'r') as zip_ref:\n    zip_ref.extractall(train_dir)\n\n# Unzipping the test dataset\nwith zipfile.ZipFile(test_zip, 'r') as zip_ref:\n    zip_ref.extractall(test_dir)\n\nprint(\"Data unzipped!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:17:01.180825Z","iopub.execute_input":"2024-11-23T22:17:01.181683Z","iopub.status.idle":"2024-11-23T22:17:15.841448Z","shell.execute_reply.started":"2024-11-23T22:17:01.181647Z","shell.execute_reply":"2024-11-23T22:17:15.840341Z"}},"outputs":[{"name":"stdout","text":"Data unzipped!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Paths to the directories\ntrain_dir = '/kaggle/working/train/train'\ntest_dir = '/kaggle/working/test'\n\n# Check the files in the train and test directories\ntrain_images = os.listdir(train_dir)\ntest1_dir = os.path.join(test_dir, 'test1')\n\n# Check contents of test1\ntest_images = os.listdir(test1_dir)\n\n# Print the number of images and a few examples to verify\nprint(f\"Number of training images: {len(train_images)}\")\nprint(f\"Number of test images: {len(test_images)}\")\n\n# Display a few examples\nprint(\"First 5 training images:\", train_images[:5])\nprint(\"First 5 test images:\", test_images[:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:14:19.018670Z","iopub.execute_input":"2024-11-23T22:14:19.019039Z","iopub.status.idle":"2024-11-23T22:14:19.045025Z","shell.execute_reply.started":"2024-11-23T22:14:19.019011Z","shell.execute_reply":"2024-11-23T22:14:19.044097Z"}},"outputs":[{"name":"stdout","text":"Number of training images: 25000\nNumber of test images: 12500\nFirst 5 training images: ['dog.6650.jpg', 'dog.4529.jpg', 'dog.5302.jpg', 'dog.1894.jpg', 'dog.5846.jpg']\nFirst 5 test images: ['3057.jpg', '4893.jpg', '454.jpg', '11706.jpg', '3471.jpg']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\n# Function to load and preprocess images\ndef load_and_preprocess_images(image_paths, target_size=(128, 128)):\n    images = []\n    for image_path in image_paths:\n        # Load image using OpenCV\n        img = cv2.imread(image_path)\n        \n        # Check if the image was loaded successfully\n        if img is None:\n            print(f\"Warning: Could not load image {image_path}\")\n            continue\n        \n        # Resize the image\n        img_resized = cv2.resize(img, target_size)\n        \n        # Normalize pixel values to [0, 1]\n        img_normalized = img_resized / 255.0\n        \n        # Flatten the image to a 1D array (for SVM)\n        img_flattened = img_normalized.flatten()\n        \n        images.append(img_flattened)\n    \n    return np.array(images)\n\n# Correct path to training images\ntrain_dir = '/kaggle/working/train/train'\ntrain_image_paths = [os.path.join(train_dir, img) for img in train_images]\nX_train = load_and_preprocess_images(train_image_paths)\n\n# Check the shape of the first preprocessed image\nprint(f\"Shape of first preprocessed image: {X_train[0].shape}\")\nprint(f\"Total number of training images: {X_train.shape[0]}\")\n\n# Correct path to test images\ntest1_dir = '/kaggle/working/test/test1'\ntest_image_paths = [os.path.join(test1_dir, img) for img in test_images]\nX_test = load_and_preprocess_images(test_image_paths)\n\nprint(f\"Total number of test images: {X_test.shape[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:14:22.334092Z","iopub.execute_input":"2024-11-23T22:14:22.335106Z","iopub.status.idle":"2024-11-23T22:15:11.286320Z","shell.execute_reply.started":"2024-11-23T22:14:22.335056Z","shell.execute_reply":"2024-11-23T22:15:11.285201Z"}},"outputs":[{"name":"stdout","text":"Shape of first preprocessed image: (49152,)\nTotal number of training images: 25000\nTotal number of test images: 12500\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\n# Step 1: Extract labels\ndef extract_labels(image_paths):\n    labels = []\n    for path in tqdm(image_paths, desc=\"Extracting labels\"):\n        filename = os.path.basename(path)\n        if filename.startswith('cat'):\n            labels.append(0)  # 0 for cats\n        elif filename.startswith('dog'):\n            labels.append(1)  # 1 for dogs\n        else:\n            print(f\"Warning: Unknown label in filename {filename}\")\n    return np.array(labels)\n\n# Extract labels for training images\ny_train = extract_labels(train_image_paths)\n\n# Step 2: Split into training and validation sets\nX_train_split, X_val, y_train_split, y_val = train_test_split(\n    X_train, y_train, test_size=0.2, random_state=42\n)\n\nprint(f\"Training set size: {X_train_split.shape[0]}\")\nprint(f\"Validation set size: {X_val.shape[0]}\")\n\n# Optional: Reduce dimensionality with PCA in batches\nprint(\"Applying PCA to reduce feature dimensions...\")\nbatch_size = 32 # Adjust batch size based on memory\npca = PCA(n_components=100, random_state=42)\n\n# Fit PCA on training data in batches\nfor start in tqdm(range(0, len(X_train_split), batch_size), desc=\"Fitting PCA\"):\n    end = min(start + batch_size, len(X_train_split))\n    if start == 0:\n        pca.partial_fit(X_train_split[start:end])  # First batch initializes PCA\n    else:\n        pca.partial_fit(X_train_split[start:end])  # Incrementally update PCA\n\n# Transform training and validation sets in batches\ndef transform_in_batches(data, pca, batch_size):\n    transformed_data = []\n    for start in tqdm(range(0, len(data), batch_size), desc=\"Transforming data\"):\n        end = min(start + batch_size, len(data))\n        transformed_data.append(pca.transform(data[start:end]))\n    return np.vstack(transformed_data)\n\nX_train_pca = transform_in_batches(X_train_split, pca, batch_size)\nX_val_pca = transform_in_batches(X_val, pca, batch_size)\n\n# Step 3: Train the SVM classifier with batch processing\nprint(\"Training the SVM classifier...\")\nsvm_model = SVC(kernel='linear', C=1.0, random_state=42)\n\n# To simulate batch training, downsample the dataset for each step.\n# SVM does not inherently support batch updates, so you must use subsets:\nfor start in tqdm(range(0, len(X_train_pca), batch_size), desc=\"Training SVM\"):\n    end = min(start + batch_size, len(X_train_pca))\n    svm_model.fit(X_train_pca[start:end], y_train_split[start:end])\n\n# Step 4: Evaluate on the validation set\nval_accuracy = svm_model.score(X_val_pca, y_val)\nprint(f\"Validation Accuracy: {val_accuracy:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:15:17.872791Z","iopub.execute_input":"2024-11-23T22:15:17.873857Z"}},"outputs":[{"name":"stderr","text":"Extracting labels: 100%|██████████| 25000/25000 [00:00<00:00, 949951.98it/s]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}